#import ("dart:math");
#import ('dart:scalarlist');

/** modified - shortened Jenkins 32 */
int _hash(List<int> key, int seed) {
  int h1 = seed;
  for (int i=0, length=key.length; i<length;++i) {
    h1 += key[i];
    h1 += (h1 << 10) & 0xfffffff;
    h1 ^= (h1 >> 6);
  }
  return h1 & 0x7fffffff;
}

int fingerPrint(List<int> key) => _hash(key, 0x9747b28c);

/**
 * A Minimal Perfect Hash function which accepts keys that can be represented as List<int>.
 * uses modified implementation of CHD algorithm. It is optimized for fast query of hash values.
 * it uses about 3.2 bits memory per key for large amount of keys.
 */
class Mphf {

  List<_HashIndexes> hashLevelData;

  Mphf.generate(KeyProvider keyProvider) {
      _BucketCalculator bc = new _BucketCalculator(keyProvider);
      this.hashLevelData = bc.calculate();
  }

  Mphf.fromStrings(Collection<String> strings) {
      _BucketCalculator bc = new _BucketCalculator(new KeyProvider.fromStrings(strings));
      this.hashLevelData = bc.calculate();
  }

  Mphf.fromIntLists(List<List<int>> intLists) {
      _BucketCalculator bc = new _BucketCalculator(new KeyProvider(intLists));
      this.hashLevelData = bc.calculate();
  }

  Mphf(this.hashLevelData);

  int get size => hashLevelData[0].keyAmount;

  int get levelCount => hashLevelData.length;

  /** returns the minimal perfect hash value for the given input [key].
   * Returning number is between [0-keycount] keycount excluded.  */
  int hashValue(List<int> key) => hashValueWithInitialHash(key, fingerPrint(key));

  /**
   * returns the minimal perfect hash value for the given input [key].
   * hash values is between [0-keycount] keycount excluded.
   * sometimes initial hash value for MPHF calculation is
   * already calculated. So [fingerprint] value is used instead of re-calculation.
   * This provides a small performance enhancement.
   */
  int hashValueWithInitialHash(List<int> key, int fingerPrint) {
    for (int i = 0; i < hashLevelData.length; i++) {
      int seed = hashLevelData[i].getSeed(fingerPrint);
      if (seed != 0) {
        if (i == 0) {
          return _hash(key, seed) % hashLevelData[0].keyAmount;
        } else {
          return hashLevelData[i - 1].failedIndexes[_hash(key, seed) % hashLevelData[i].keyAmount];
        }
      }
    }
    throw new ExpectException("Cannot be here.");
  }

  num totalBytesUsed() {
    num result = 0;
    for (_HashIndexes data in hashLevelData) {
      result += data.bucketHashSeedValues.length;
      result += data.failedIndexes.length * 4;
    }
    return result;
  }

  double averageBitsPerKey() => (totalBytesUsed() * 8).toDouble() / hashLevelData[0].keyAmount;
}

class _HashIndexes {
  int keyAmount;
  int bucketAmount;
  Uint8List bucketHashSeedValues;
  List<int> failedIndexes;

  _HashIndexes(this.keyAmount, this.bucketAmount, this.bucketHashSeedValues, this.failedIndexes);

  int getSeed(int fingerPrint) => (bucketHashSeedValues[fingerPrint % bucketAmount]) & 0xff;

}

class _BucketCalculator {

  KeyProvider keyProvider;
  int keyAmount;
  double averageKeysPerBucket;
  static final int HASH_SEED_LIMIT = 255;

  _BucketCalculator(this.keyProvider){
    averageKeysPerBucket = 3.0;
  }

  List<_HashIndexes> calculate() {
    keyAmount = keyProvider.keyAmount();

    int bucketAmount=(keyAmount / averageKeysPerBucket).toInt();

    var buckets = generateInitialBuckets(bucketAmount);

    // sort buckets larger to smaller.
    buckets.sort((_Bucket a, _Bucket b) => a.compareTo(b));

    var result = new List<_HashIndexes>();

    calculateIndexes(buckets, keyAmount, result);

    return result;
  }

  List<_Bucket> generateInitialBuckets(int bucketAmount) {

    // Generating buckets
    var buckets = new List<_Bucket>(bucketAmount);
    for (int i = 0; i < buckets.length; i++) {
      buckets[i] = new _Bucket(i);
    }

    // add keys to buckets.
    for (int i = 0; i < keyAmount; i++) {
      int bucketIndex = fingerPrint(keyProvider.getKey(i)) % bucketAmount;
      buckets[bucketIndex].add(i);
    }    

    return buckets;
  }

  void calculateIndexes(List<_Bucket> buckets, int keyAmount, List<_HashIndexes> indexes) {

    // generate a long bit vector with size of hash target size.
    _FixedBitVector bitVector = new _FixedBitVector.bitCount(keyAmount);

    var hashSeedArray = new Uint8List(buckets.length);
    for(int k = 0; k<hashSeedArray.length;++k)
      hashSeedArray[k]=1;

    // we need to collect failed buckets (A failed bucket such that we cannot find empty slots for all bucket keys
    // after 255 trials. )
    var failedBuckets = new List<_Bucket>();

    // for each bucket, find a hash function that will map each key in it to an empty slot in bitVector.
    for (_Bucket bucket in buckets) {
      if (bucket.itemIndexes.length == 0) // because buckets are sorted, we can finish here.
        break;
      int hashSeedIndex = 1;
      bool loop = true;
      while (loop) {
        var slots = new List<int>();
        for (int keyIndex in bucket.itemIndexes) {
          var key = keyProvider.getKey(keyIndex);
          int bitIndex = _hash(key, hashSeedIndex) % keyAmount;
          if (bitVector.getBit(bitIndex))
            break;
          else {
            slots.add(bitIndex);
            bitVector.setBit(bitIndex);
          }
        }
        // if we fail to place all items in the bucket to the bitvector"s empty slots
        if (slots.length < bucket.itemIndexes.length) {
          // we reset the occupied slots from bitvector.
          for (int bitIndex in slots) {
            bitVector.clear(bitIndex);
          }
          // We reached the HASH_SEED_LIMIT.
          // We place a 0 for its hash index value to know later that bucket is left to secondary lookup.
          if (hashSeedIndex == HASH_SEED_LIMIT) {
            failedBuckets.add(bucket);
            hashSeedArray[bucket.id] = 0;
            loop = false;
          }

        } else { // sweet. We have found empty slots in bit vector for all keys of the bucket.
          hashSeedArray[bucket.id] = hashSeedIndex;
          loop = false;
        }
        hashSeedIndex++;
      }
    }

    if (failedBuckets.length == 0) {
      // we are done.
      indexes.add(new _HashIndexes(keyAmount, buckets.length, hashSeedArray, new List(0)));
      return;
    }

    // we assign lower average per key per bucket after each iteration to avoid generation failure.
    if (averageKeysPerBucket > 1)
      averageKeysPerBucket--;

    // start calculation for failed buckets.
    int failedKeyCount = 0;
    for (_Bucket failedBucket in failedBuckets) {
      failedKeyCount += failedBucket.itemIndexes.length;
    }

    int failedBucketAmount = (failedKeyCount / averageKeysPerBucket).toInt();

    // this is a worst case scenario. No empty slot find for any buckets and we are already using buckets where bucket Amount>=keyAmount
    // In this case we double the bucket size with the hope that it will have better bucket-key distribution.
    if (failedKeyCount == keyAmount && averageKeysPerBucket <= 1) {
      averageKeysPerBucket = averageKeysPerBucket / 2;
      failedBucketAmount *= 2;
    }

    if (failedBucketAmount == 0)
      failedBucketAmount++;

    // this time we generate item keyAmount of Buckets
    var nextLevelBuckets = new List<_Bucket>(failedBucketAmount);
    for (int i = 0; i < failedBucketAmount; i++) {
      nextLevelBuckets[i] = new _Bucket(i);
    }

    // generate secondary buckets with item indexes.
    for (_Bucket largeHashIndexBucket in failedBuckets) {
      for (int itemIndex in largeHashIndexBucket.itemIndexes) {
        int secondaryBucketIndex = fingerPrint(keyProvider.getKey(itemIndex)) % failedBucketAmount;
        nextLevelBuckets[secondaryBucketIndex].add(itemIndex);
      }
    }

    // sort buckets larger to smaller.
    nextLevelBuckets.sort((_Bucket a, _Bucket b) => a.compareTo(b));

    int currentLevel = indexes.length;
    var failedHashValues = new List<int>();
    for (int i = 0; i < bitVector.size; i++) {
      if (!bitVector.getBit(i)) {
        failedHashValues.add(currentLevel==0 ? i : indexes[currentLevel - 1].failedIndexes[i]);
      }
    }

    indexes.add(new _HashIndexes(keyAmount, buckets.length, hashSeedArray, failedHashValues));

    // recurse for failed buckets.
    calculateIndexes(nextLevelBuckets, failedKeyCount, indexes);
  }
}

/** A bucket that holds keys. It contains a small array for keys. */
class _Bucket implements Comparable {
    int id;
    var itemIndexes = new List<int>();
    _Bucket(this.id);
    void add(int i) { itemIndexes.add(i); }
    int compareTo(_Bucket o) => o.itemIndexes.length.compareTo(itemIndexes.length);
}

class _FixedBitVector {
  Int32List _words;
  int _size;

  var _setMasks = new Int32List(32);
  var _resetMasks = new Int32List(32);

  _initialize(int capacity) {
      _size = capacity;
      int wordCount = capacity~/32 + 1;
      _words = new Int32List(wordCount);
      for (int i = 0; i < 32; i++) {
        _setMasks[i] = 0x1 << i;
        _resetMasks[i] = ~_setMasks[i];
      }
  }
  
  get size => _size;

  /** Creates a fixed bit vector with capacity of [bitCount]. */
  _FixedBitVector.bitCount(int bitCount) {
    _initialize(bitCount);
  }

  bool getBit (int n) => (_words[n >> 5] & _setMasks[n & 31]) != 0;

  void setBit (int n) {
    _words[n >> 5] |= _setMasks[n & 31];
  }

  void clear(int n) {
    _words[n >> 5] &= _resetMasks[n & 31];
  }

}

class KeyProvider {
   List<List<int>> list = new List();
   KeyProvider(this.list);

   KeyProvider.fromStrings(Collection<String> vals) {
     for(String s in vals) {
       list.add(s.charCodes());
     }
   }

   List<int> getKey(int index) => list[index];

   int keyAmount() => list.length;
}

void main() {

  var testStrings = randomStrings();
  
  for(int k=0; k<5; k++) {
    var stopWatch = new Stopwatch();
    stopWatch.start();
    var hash = new Mphf.fromStrings(testStrings);
    print("Hash generation time : ${stopWatch.elapsedInMs()} ms");
    print("Average bit per key: ${hash.averageBitsPerKey()}");
  
    List<List<int>> l = new List();
    for(String s in testStrings) {
      l.add(s.charCodes());
    }
    stopWatch..reset()..start();    
    for(int i = 0, length = l.length; i<length; ++i) {
      int k = hash.hashValue(l[i]);
    }
    print("Hash query time : ${stopWatch.elapsedInMs()} ms");
  }
}

Set<String> randomStrings() {
  var rnd = new Random();
  var testVals = new Set<String>();
  while(testVals.length<100000) {
    var buffer = new StringBuffer();
    for(int k = 0; k<7; k++) {
      int randomChar = rnd.nextInt(26)+'a'.charCodeAt(0);
      buffer.addCharCode(randomChar);
    }
    testVals.add(buffer.toString());
  }
  return testVals;
}

void fruitTest() {
  var fruits = ["apple", "orange", "blueberry", "cherry", "pomegranate", "plum", "pear"];
  var mphf = new Mphf.fromStrings(fruits);
  for(var fruit in fruits) {
    print("$fruit = ${mphf.hashValue(fruit.charCodes())}");
  }
}